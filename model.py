# -*- coding: utf-8 -*-
"""model.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1uedHaWmzFve5YwekM-vzpRW1Fp5d8K0H

# Sentiment based product recommendation system: 

* A company launches its website to sell the items to the end consumer, and customers can order the products that they require from the same website
* Here we are going to build a model that will improve the recommendations to the users given their past reviews and ratings (sentiment) based products.
"""

# Importing the required libraries
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

import warnings
warnings.filterwarnings("ignore")

# import required libraries
import string
import re
from wordcloud import WordCloud, STOPWORDS
import spacy
from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer

from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import TfidfTransformer
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import confusion_matrix, accuracy_score
from sklearn.metrics import classification_report
from sklearn.model_selection import GridSearchCV
from sklearn.ensemble import RandomForestClassifier

from collections import Counter
from imblearn.over_sampling import SMOTE

from sklearn.naive_bayes import MultinomialNB

from xgboost import XGBClassifier

import pickle
from scipy import sparse

# NLTK libraries
import nltk
nltk.download('stopwords')
nltk.download('punkt')
nltk.download('averaged_perceptron_tagger')
nltk.download('wordnet')
from nltk.corpus import stopwords
from nltk import FreqDist
from nltk.tokenize import word_tokenize
from nltk.stem.wordnet import WordNetLemmatizer
from nltk.corpus import wordnet

# Connecting to google drive
from google.colab import drive
drive.mount('/content/drive')

# importing dataset
df = pd.read_csv("/content/drive/MyDrive/Capstone/sample30.csv")

#Exploring data
df.head()

"""## Exploratory Data analysis"""

# Understanding the given dataset
df.info()

print(df.shape)
print(df.dtypes)

# Checking missing values
df.isnull().sum()

"""As shown above, manufacturer, reviews_didPurchase, reviews_doRecommend, reviews_userCity, reviews_userProvince, reviews_username, user_sentiment columns having missing values. 

We can drop the columns like reviews_userCity, reviews_userProvince which are having null values and not required for further analysis.

## Data Cleaning
"""

## "reviews_userCity" and "reviews_userProvince" having lot of missing values. We can drop these columns from further processsing.
df = df.drop(['reviews_userCity','reviews_userProvince'],axis=1)

# Selecting Required columns for further analysis
#df = df[['name','reviews_didPurchase','reviews_rating','reviews_text','user_sentiment']]
df.head()

# Checking missing values again
df.isnull().sum()

## user_sentiment is our target column for building the model. So we can remove missing values in this column
df=df.dropna(subset=['user_sentiment'])

# Replacing missing values of reviews_didPurchase with proper meaning
df['reviews_didPurchase'] = df['reviews_didPurchase'].fillna('Reviews N/A')

# Since we need to use reviews_username for recommendations in upcoming steps, so taking care of missing values in this column,
df=df.dropna(subset=['reviews_username'])

# Checking missing values again
df.isnull().sum()

# Identifying all ratings and their counts
df['reviews_rating'].value_counts()

# Checking review ratings
ratingInfo = df['reviews_rating'].value_counts()
ratingInfo
sns.barplot(x=ratingInfo.index, y=ratingInfo.values)

# Plotting the reviews of purchase
review_plt = sns.countplot(df['reviews_didPurchase'])
review_plt.set_xlabel(xlabel="User Reviews",fontsize=12)
review_plt.set_ylabel(ylabel='No of Reviews',fontsize=12)

"""Here we can observe that, True reviews are less. So Users who didn't even purchase product also provided reviews."""

# Creating a new column "reviews_length" which contains length of reviews being given against each product.
df['reviews_length']=df['reviews_text'].apply(len)

## Plotting above created review_length column to see the distibution for each individual rating and word length
sns.set(font_scale=2.0)
reviews_graph=sns.FacetGrid(df, col='reviews_rating', size=5)
reviews_graph.map(plt.hist, 'reviews_length')
plt.show()

# Checking number of unique products
print('Number of products => ',len(df['name'].unique()))

# Considering 3 and above ratings as Positive sentiments and below them as Negative.
# we see that below count gives a picture of mismatched labels
len(df[(df['reviews_rating']<3)&(df['user_sentiment']=='Positive')])

# Correcting the user_sentiment column to reflect the correct label
df['user_sentiment'] = np.where(((df['reviews_rating']<3)&(df['user_sentiment']=='Positive')) , 'Negative', df['user_sentiment'])

# Re-checking to see impact to the above changes
len(df[(df['reviews_rating']<3)&(df['user_sentiment']=='Positive')])

## Print the number of positive feedback
pos = len(df[df['user_sentiment']=='Positive'])
print('Number of positive sentiments: {}'.format(pos))

## Print the number of negative feedback
neg = len(df[df['user_sentiment']=='Negative'])     
print('\nNumber of negative sentiments: {}'.format(neg))

# Statistics of non-numeric variables

# Number of unique customers
print('\nNumber of unique customers : {}'.format(len(df['reviews_username'].unique())))

# Number of unique products
print('\nNumber of unique products : {}'.format(len(df['categories'].unique())))
      
# Review number per unique customer
print('\nReview per customer: {}'.format((len(df)/len(df['reviews_username'].unique()))))      

# Review number per unique product 
print('\nReview per product: {}'.format((len(df)/len(df['categories'].unique()))))

"""## Text Preprocessing"""

for index,text in enumerate(df['reviews_text'][35:40]):
  print('Review %d:\n'%(index+1),text)

"""In above review text we can observe that, contractions like punctuations present. we are going to handle them below, """

contractions_dict = {"ain't": "is not","aren't": "are not","can't": "cannot","can't've": "cannot have",
"'cause": "because","could've": "could have","couldn't": "could not","couldn't've": "could not have","didn't": "did not",
"doesn't": "does not","don't": "do not","hadn't": "had not","hadn't've": "had not have","hasn't": "has not","haven't": "have not","he'd": "he would",
"he'd've": "he would have","he'll": "he will","he'll've": "he he will have","he's": "he is","how'd": "how did","how'd'y": "how do you","how'll": "how will",
"how's": "how is","I'd": "I would","I'd've": "I would have","I'll": "I will","I'll've": "I will have","I'm": "I am","I've": "I have","i'd": "i would",
"i'd've": "i would have","i'll": "i will","i'll've": "i will have","i'm": "i am","i've": "i have","isn't": "is not","it'd": "it would",
"it'd've": "it would have","it'll": "it will","it'll've": "it will have","it's": "it is","let's": "let us","ma'am": "madam","mayn't": "may not","might've": "might have",
"mightn't": "might not","mightn't've": "might not have","must've": "must have","mustn't": "must not","mustn't've": "must not have","needn't": "need not",
"needn't've": "need not have","o'clock": "of the clock","oughtn't": "ought not","oughtn't've": "ought not have","shan't": "shall not","sha'n't": "shall not",
"shan't've": "shall not have","she'd": "she would","she'd've": "she would have","she'll": "she will","she'll've": "she will have","she's": "she is",
"should've": "should have","shouldn't": "should not","shouldn't've": "should not have","so've": "so have","so's": "so as",
"that'd": "that would","that'd've": "that would have","that's": "that is","there'd": "there would","there'd've": "there would have",
"there's": "there is","they'd": "they would","they'd've": "they would have","they'll": "they will","they'll've": "they will have","they're": "they are",
"they've": "they have","to've": "to have","wasn't": "was not","we'd": "we would","we'd've": "we would have","we'll": "we will","we'll've": "we will have",
"we're": "we are","we've": "we have","weren't": "were not","what'll": "what will","what'll've": "what will have","what're": "what are",
"what's": "what is","what've": "what have","when's": "when is","when've": "when have","where'd": "where did","where's": "where is",
"where've": "where have","who'll": "who will","who'll've": "who will have","who's": "who is","who've": "who have","why's": "why is",
"why've": "why have","will've": "will have","won't": "will not","won't've": "will not have","would've": "would have",
"wouldn't": "would not","wouldn't've": "would not have","y'all": "you all","y'all'd": "you all would","y'all'd've": "you all would have","y'all're": "you all are",
"y'all've": "you all have","you'd": "you would","you'd've": "you would have","you'll": "you will","you'll've": "you will have","you're": "you are","you've": "you have"
}

# Function for expanding contractions
def expand_contractions(text):
  contractions_pattern = re.compile('({})'.format('|'.join(contractions_dict.keys())),flags=re.IGNORECASE|re.DOTALL)
  def expand_match(contraction):
        match = contraction.group(0)
        first_char = match[0]
        expanded_contraction = contractions_dict.get(match)\
                        if contractions_dict.get(match)\
                        else contractions_dict.get(match.lower())
        expanded_contraction = first_char+expanded_contraction[1:]
        return expanded_contraction
    
  expanded_text = contractions_pattern.sub(expand_match, text)
  expanded_text = re.sub("'", "", expanded_text)
  return expanded_text

# Expanding Contractions in the reviews
df['clean_reviews_text']=df['reviews_text'].apply(lambda x:expand_contractions(x))

# Since NLP is case sensitive of words, we need to convert all ratings_text data into lowercase as below,
df['clean_reviews_text']=df['clean_reviews_text'].apply(lambda x: x.lower())

# Removing sqare brackets
df['clean_reviews_text']=df['clean_reviews_text'].apply(lambda x: re.sub('\[[^]]*\]', '', x))

# we need to remove numbers and words containing digits from the reviews
df['clean_reviews_text']=df['clean_reviews_text'].apply(lambda x: re.sub('\w*\d\w*','', x))

# Removing punchtuations
df['clean_reviews_text']=df['clean_reviews_text'].apply(lambda x: re.sub('[%s]' % re.escape(string.punctuation), '', x))

# string.punctuations function contains all the punctuations and we use regular expressions to search them in the text and remove them. 
# Finally, we still have some extra spaces present in the data.
# Removing extra spaces
df['clean_reviews_text']=df['clean_reviews_text'].apply(lambda x: re.sub(' +',' ',x))

# Now, checking text data after cleaning,
for index,text in enumerate(df['clean_reviews_text'][35:40]):
  print('Review %d:\n'%(index+1),text)

"""#### Next, we’ll do the following steps:

* Stopwords Removal
* Lemmatization
* Feature Extraction
"""

# Loading model
nlp = spacy.load('en_core_web_sm',disable=['parser', 'ner'])

# Lemmatization with stopwords removal
df['clean_reviews_text']=df['clean_reviews_text'].apply(lambda x: ' '.join([token.lemma_ for token in list(nlp(x)) if (token.is_stop==False)]))

df['clean_reviews_text']

# Using a word cloud find the top 40 words by frequency among all the articles after processing the text
stopwords = set(STOPWORDS)

def show_wordcloud(data, title = None):
    wordcloud = WordCloud(
        background_color='black',
        stopwords=stopwords,
        max_words=40,
        max_font_size=40, 
        scale=3,
        random_state=1
    ).generate(str(data))

    fig = plt.figure(1, figsize=(12, 12))
    plt.axis('off')
    if title: 
        fig.suptitle(title, fontsize=20)
        fig.subplots_adjust(top=2.3)

    plt.imshow(wordcloud)

#show_wordcloud(' '.join(df1['reviews_text'].values))
show_wordcloud(df['clean_reviews_text'])
plt.title ('WordCloud for product review',size = 16)
plt.show()

# Creating new csv file with updated clean_review_text column 
# To use this csv file further in flask application
df.to_csv("/content/drive/MyDrive/Capstone/updated_sample30.csv")

"""## Feature Extraction
Convert the raw texts to a matrix of TF-IDF features

**max_df** is used for removing terms that appear too frequently, also known as "corpus-specific stop words"
max_df = 0.95 means "ignore terms that appear in more than 95% of the complaints"

**min_df** is used for removing terms that appear too infrequently
min_df = 2 means "ignore terms that appear in less than 2 complaints"

## Supervised model to predict any reviews to the relevant product.

Since we will be using supervised learning technique we have to convert the product names to numbers(numpy arrays only understand numbers)
"""

# Keep the columns"reviews_text" & "reviews_rating" only in the new dataframe --> training_data
training_data=df[['clean_reviews_text','user_sentiment']]

# Checking training_data
training_data

# Checking training_data rows & columns
training_data.shape

"""#### Apply the supervised models on the training data created. In this process, we have to do the following:
* Divide data into trsaining and testing parts
* Transform the word vecotr to tf-idf
* Create the train & test data using the train_test_split on the tf-idf & topics

"""

# Split the dataset into test and train
seed = 50 
X=training_data['clean_reviews_text']
y=training_data['user_sentiment']

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=seed)

y_train.value_counts()

"""The above clearly shows that there is more of positive sentiments then negative .So we have to take care of this imbalance issue.

Here we will be using SMOTE technique for the same.
"""

# Create the word vector with TF-IDF Vectorizer
word_vectorizer = TfidfVectorizer(
    strip_accents='unicode',    # Remove accents and perform other character normalization during the preprocessing step. 
    analyzer='word',            # Whether the feature should be made of word or character n-grams.
    token_pattern=r'\w{1,}',    # Regular expression denoting what constitutes a “token”, only used if analyzer == 'word'
    ngram_range=(1, 3),         # The lower and upper boundary of the range of n-values for different n-grams to be extracted
    stop_words='english',
    sublinear_tf=True)

word_vectorizer.fit(X_train)    # Fiting it on Train
train_word_features = word_vectorizer.transform(X_train)  # Transform on Train

# Preparing pkl file to save the word_vectorizer model
word_pkl_fileName = "/content/drive/MyDrive/Capstone/word_vectorizer.pkl"
with open(word_pkl_fileName, 'wb') as file:
  pickle.dump(word_vectorizer, file)

# Transforming the train and test datasets
X_train_transformed = word_vectorizer.transform(X_train.tolist())
X_test_transformed = word_vectorizer.transform(X_test.tolist())

# Print the shape of each dataset.
print('X_train_transformed', X_train_transformed.shape)
print('y_train', y_train.shape)
print('X_test_transformed', X_test_transformed.shape)
print('y_test', y_test.shape)

"""Building ML model on the train & test data from these options:
* XGBoost

### Training a text classification model: 
* Building model and evaluating them using the required metrics & performance

### SMOTE technique applied to fix class imbalance/over sampling issue
"""

## Using SMOTE technique - to overcome class imbalance issue and over sampling issue

counter = Counter(y_train)
print('Before',counter)

sm = SMOTE()

# transform the dataset
X_train_sm, y_train_sm = sm.fit_resample(X_train_transformed, y_train)

counter = Counter(y_train_sm)
print('After',counter)

"""# Training text classification model with SMOTE

### XGBoost
"""

xgb=XGBClassifier()

xgb.fit(X_train_sm,y_train_sm)

# Prediction Train Data
xgb_prediction= xgb.predict(X_train_sm)

print("XGBoost Model train accuracy", accuracy_score(xgb_prediction,y_train_sm))
print(classification_report(xgb_prediction,y_train_sm))
print(confusion_matrix(xgb_prediction,y_train_sm))

# Prediction Test Data
y_pred_test_xgb = xgb.predict(X_test_transformed)

print("XGBoost Model test accuracy", accuracy_score(y_pred_test_xgb, y_test))
print(classification_report(y_pred_test_xgb, y_test))
print(confusion_matrix(y_pred_test_xgb, y_test))

train_acc_xgb,test_acc_xgb=accuracy_score(xgb_prediction,y_train_sm),accuracy_score(y_pred_test_xgb, y_test)
print("XGBoost Train Accuracy :{}".format(train_acc_xgb))
print("XGBoost Test Accuracy :{}".format(test_acc_xgb))

"""### Comparing all evaluated models:"""

### Writing the results in dataframe to visualize it further
models = ['XGBoost']
result_df = pd.DataFrame(index=range(1* len(models)))
entries=[]
entries.append((models[0], train_acc_xgb,test_acc_xgb))
result_df = pd.DataFrame(entries, columns=['model_name', 'train_accuracy', 'test_accuracy'])
result_df

# Plotting the train accuracy's of the models
sns.boxplot(x='model_name', y='train_accuracy', data=result_df)
sns.stripplot(x='model_name', y='train_accuracy', data=result_df, 
              size=8, jitter=True, edgecolor="gray", linewidth=2)
plt.xticks(rotation=90)
plt.show()

# Plotting the test accuracy's of the models
sns.boxplot(x='model_name', y='test_accuracy', data=result_df)
sns.stripplot(x='model_name', y='test_accuracy', data=result_df, 
              size=8, jitter=True, edgecolor="gray", linewidth=2)
plt.xticks(rotation=90)
plt.show()

"""* After building all the 4 models, we can observe that, **XGBoost is best fitting model** for the given dataset. We can select this classification model based on its performance accuracy 0.87/0.84 on train and test data, and f1-score is also good with approx 0.90. """

# Preparing pkl file to save the XGBoost model
pkl_fileName = "/content/drive/MyDrive/Capstone/xgboost_sentiment_model.pkl"
with open(pkl_fileName, 'wb') as file:
  pickle.dump(xgb, file)

# As above, results showing in Logistic Regression gives the best predictions
result = pd.DataFrame( {'review':X_test,'true_labels': y_test,'predicted_labels': y_pred_test_xgb})
result.head(20)

"""# Recommendation System
- User based recommendation
- User based prediction & evaluation
- Item based recommendation
- Item based prediction & evaluation

Different Approaches to develop Recommendation System -

1. Demographich based Recommendation System

2. Content Based Recommendation System

3. Collaborative filtering Recommendation System

## Dividing the dataset into train and test
"""

# Test and Train split of the dataset.
from sklearn.model_selection import train_test_split
train, test = train_test_split(df, test_size=0.30, random_state=31)

print(train.shape)
print(test.shape)

# Pivot the train ratings' dataset into matrix format in which columns are products and the rows are user IDs.
df_pivot = train.pivot_table(
    index='reviews_username',
    columns='name',
    values='reviews_rating',
).fillna(0)

"""### Creating dummy train & dummy test dataset
These dataset will be used for prediction 
- Dummy train will be used later for prediction of the products which has not been rated by the user. To ignore the product rated by the user, we will mark it as 0 during prediction. The product not rated by user is marked as 1 for prediction in dummy train dataset. 

- Dummy test will be used for evaluation. To evaluate, we will only make prediction on the products rated by the user. So, this is marked as 1. This is just opposite of dummy_train.
"""

# Copy the train dataset into dummy_train
dummy_train = train.copy()

dummy_train.head()

# The products not rated by user is marked as 1 for prediction. 
dummy_train['reviews_rating'] = dummy_train['reviews_rating'].apply(lambda x: 0 if x>=1 else 1)

# Convert the dummy train dataset into matrix format.
dummy_train = dummy_train.pivot_table(
    index='reviews_username',
    columns='name',
    values='reviews_rating'
).fillna(1)

dummy_train.head()

"""**Cosine Similarity**

Cosine Similarity is a measurement that quantifies the similarity between two vectors [Which is Rating Vector in this case] 

**Adjusted Cosine**

Adjusted cosine similarity is a modified version of vector-based similarity where we incorporate the fact that different users have different ratings schemes. In other words, some users might rate items highly in general, and others might give items lower ratings as a preference. To handle this nature from rating given by user , we subtract average ratings for each user from each user's rating for different products.

## Using Item similarity

# Item Based Similarity

Taking the transpose of the rating matrix to normalize the rating around the mean for different product ID. In the user based similarity, we had taken mean for each user instead of each product.
"""

df_pivot = train.pivot_table(
    index='reviews_username',
    columns='name',
    values='reviews_rating'
).T

df_pivot.head()

"""Normalising the product rating for each product for using the Adujsted Cosine"""

mean = np.nanmean(df_pivot, axis=1)
df_subtracted = (df_pivot.T-mean).T

df_subtracted.head()

"""Finding the cosine similarity using pairwise distances approach"""

from sklearn.metrics.pairwise import pairwise_distances

# Item Similarity Matrix
item_correlation = 1 - pairwise_distances(df_subtracted.fillna(0), metric='cosine')
item_correlation[np.isnan(item_correlation)] = 0
print(item_correlation)

item_correlation.shape

"""Filtering the correlation only for which the value is greater than 0. (Positively correlated)"""

item_correlation[item_correlation<0]=0
item_correlation

"""# Prediction - Item Item"""

item_predicted_ratings = np.dot((df_pivot.fillna(0).T),item_correlation)
item_predicted_ratings

item_predicted_ratings.shape

dummy_train.shape

"""### Filtering the rating only for the products not rated by the user for recommendation"""

item_final_rating = np.multiply(item_predicted_ratings,dummy_train)
item_final_rating.head()

"""### Finding the top 20 product recommendation for the *user*"""

# Recommending the Top 20 products to a sample user.
d = item_final_rating.loc['01impala'].sort_values(ascending=False)[0:20]
d

"""# Evaluation - Item Item

Evaluation will we same as you have seen above for the prediction. The only difference being, you will evaluate for the product already rated by the user insead of predicting it for the product not rated by the user.
"""

test.columns

common =  test[test.name.isin(train.name)]
common.shape

common.head(4)

common_item_based_matrix = common.pivot_table(index='reviews_username', columns='name', values='reviews_rating').T

common_item_based_matrix.shape

item_correlation_df = pd.DataFrame(item_correlation)

item_correlation_df.head(1)

item_correlation_df['reviews_username'] = df_subtracted.index
item_correlation_df.set_index('reviews_username',inplace=True)
item_correlation_df.head()

list_name = common.name.tolist()

item_correlation_df.columns = df_subtracted.index.tolist()

item_correlation_df_1 =  item_correlation_df[item_correlation_df.index.isin(list_name)]

item_correlation_df_2 = item_correlation_df_1.T[item_correlation_df_1.T.index.isin(list_name)]

item_correlation_df_3 = item_correlation_df_2.T

item_correlation_df_3.head()

item_correlation_df_3[item_correlation_df_3<0]=0

common_item_predicted_ratings = np.dot(item_correlation_df_3, common_item_based_matrix.fillna(0))
common_item_predicted_ratings

common_item_predicted_ratings.shape

"""Dummy test will be used for evaluation. To evaluate, we will only make prediction on the products rated by the user. So, this is marked as 1. This is just opposite of dummy_train


"""

dummy_test = common.copy()

dummy_test['reviews_rating'] = dummy_test['reviews_rating'].apply(lambda x: 1 if x>=1 else 0)

dummy_test = dummy_test.pivot_table(index='reviews_username', columns='name', values='reviews_rating').T.fillna(0)

common_item_predicted_ratings = np.multiply(common_item_predicted_ratings,dummy_test)

"""The products not rated is marked as 0 for evaluation. And make the item- item matrix representaion.

"""

common_ = common.pivot_table(index='reviews_username', columns='name', values='reviews_rating').T

from sklearn.preprocessing import MinMaxScaler
from numpy import *

X  = common_item_predicted_ratings.copy() 
X = X[X>0]

scaler = MinMaxScaler(feature_range=(1, 5))
print(scaler.fit(X))
y = (scaler.transform(X))

print(y)

# Finding total non-NaN value
total_non_nan = np.count_nonzero(~np.isnan(y))

rmse = (sum(sum((common_ - y )**2))/total_non_nan)**0.5
print(rmse)

"""##**Summary - Recommendation Engine**

* After evaluating both user based and item based recommendation systems, we can observe the RMSE scores are as below,
  * User based RMSE = 2.3725228370669296
  * Item based RMSE = 3.563307280013942

* Lower values of RMSE score indicates better fit. RMSE is one of the measure to predict model. But in the given case study, user recommendation not giving expected results though it's RMSE score is less.

* For comutational purpose and more accurate results we have choosen **Item based recommendation system**.
"""

# Preparing pkl file to save the Item based recommendation system
item_final_rating.to_pickle("/content/drive/MyDrive/Capstone/Item_Recommendation.pkl")

# Loading the recommendation pickle file
pipeline = pickle.load(open('/content/drive/MyDrive/Capstone/Item_Recommendation.pkl', 'rb'))
pipeline

# Recommending the Top 20 products to the sample user.
user_top_products_data = pipeline.loc['01impala'].sort_values(ascending=False)[0:20]
user_top_products_data = user_top_products_data.to_frame()
user_top_products_data = user_top_products_data.reset_index()

user_top_products_data

# Loading word vectorization pickle file
vector_pipeline = pickle.load(open('/content/drive/MyDrive/Capstone/word_vectorizer.pkl', 'rb'))
vector_pipeline

# Loading sentiment based ML model pickle file
sentiment_pipeline = pickle.load(open('/content/drive/MyDrive/Capstone/xgboost_sentiment_model.pkl', 'rb'))
sentiment_pipeline

user_top_products_data.name

# Code for computing the percentage of Positive review ratings for top 20 products. 
final_df = pd.DataFrame()
for prod_name in user_top_products_data['name']:
  row_data = df[df['name'] == prod_name]
  vector_sentance = vector_pipeline.transform(row_data['clean_reviews_text'])
  sentiment_prediction = sentiment_pipeline.predict(vector_sentance)
  percentage = (sentiment_prediction.tolist().count('Positive') / len(sentiment_prediction.tolist())) * 100
  print("percentage of postive: ", percentage)
  data = {'prod_name': prod_name, 'pos_percent':percentage}
  final_df = final_df.append(data, ignore_index=True)

# Getting the top 5 products recommended based on sentiment for given user. 
final_df = final_df.sort_values(by=['pos_percent'], ascending=False)
final_df

# Top 5 recommended products based on sentiments 
final_df['prod_name'][:5]